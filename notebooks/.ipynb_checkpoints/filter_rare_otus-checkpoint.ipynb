{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7be737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9688ac05",
   "metadata": {},
   "source": [
    "# Filtering rare OTUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb273f",
   "metadata": {},
   "source": [
    "## Calculate percentage of the singeltons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ac166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "\n",
    "project = 'Suthaus_2022'\n",
    "cell = 'cell'\n",
    "marker = 'rDNA'\n",
    "sim = 'sim90'\n",
    "raw_data = '../raw_data'\n",
    "otu_preclust_dir = f'{raw_data}/OTU_preclust/{project}/{marker}/{cell}/{sim}'\n",
    "tax_assign_dir = f'{raw_data}/tax_assign_results/{project}/{marker}/{cell}/{sim}'\n",
    "filt_otu_dir = f'{raw_data}/OTU_filtered/{project}/{marker}/{cell}/{sim}'\n",
    "vamp_spec_dir = f'{raw_data}/vamp_specific_seqs/{project}/{marker}/{cell}/{sim}'\n",
    "otu_chim_filt = f'{raw_data}/OTU_nonchimeric/{project}/{marker}/{cell}/{sim}'\n",
    "extracted_18S = f'{raw_data}/extracted_18S/{project}/{marker}/{cell}/{sim}'\n",
    "filt_otu_dir_18S = f'{raw_data}/OTU_filtered/{project}/18S_from_rDNA/{cell}/{sim}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43875d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "\n",
    "\n",
    "def strip(file_path, output_path):\n",
    "    '''\n",
    "    Remove line breaks in FASTA files, so it will be easier to filter singeltons in the next step\n",
    "    '''\n",
    "    seqs = []\n",
    "    # read a file and stripped it\n",
    "    with open(file_path,'rt') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('>'):\n",
    "                seqs.append('\\n' + line)\n",
    "            else:\n",
    "                line_cleaned = line.rstrip()\n",
    "                seqs.append(line_cleaned)\n",
    "        seqs[0] = seqs[0].lstrip()\n",
    "    # write the file into fasta\n",
    "    # get sample name for Jamy data:\n",
    "    # sample_name = file_path.split('_')[-1].split('.')[0]\n",
    "    # get sample name for our data:\n",
    "    sample_name = file_path.split('/')[-1].lstrip('otu_').rstrip('.fasta')\n",
    "    with open(f'{output_path}/otu_{sample_name}.fasta', 'w') as fp:\n",
    "        for seq in seqs:\n",
    "            fp.write(seq)\n",
    "            \n",
    "            \n",
    "def filter_rare(path, output_path, threshold=1):\n",
    "    seqs_nonsingl = []\n",
    "    with open(path,'rt') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[::-1]:\n",
    "            if not line.startswith('>'):\n",
    "                seq_ = line\n",
    "            if ('>' in line):\n",
    "                abundance = int(line.split('=')[-1].rstrip('\\n'))\n",
    "                if abundance > threshold:\n",
    "#             if ('>' in line) and (not line.endswith(f'seqs={threshold}\\n')):\n",
    "                    seqs_nonsingl.append(line)\n",
    "                    seqs_nonsingl.append(seq_)\n",
    "    # write the file into fasta\n",
    "    # get sample name for our data:\n",
    "    sample_name = path.split('/')[-1].lstrip('otu_').rstrip('.fasta')\n",
    "    with open(f'{output_path}/nonrare_otu_{sample_name}.fasta', 'w') as fp:\n",
    "        for seq in seqs_nonsingl:\n",
    "            fp.write(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02c0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths\n",
    "all_files = os.listdir(otu_chim_filt)\n",
    "all_paths = [otu_chim_filt + '/' + path for path in all_files]\n",
    "all_paths = [path for path in all_paths if '.fasta' in path]\n",
    "all_paths\n",
    "\n",
    "# create an output directory if not exist:\n",
    "is_exist = os.path.exists(filt_otu_dir)\n",
    "if not is_exist:\n",
    "    os.makedirs(filt_otu_dir)\n",
    "    print(f'directory created: {filt_otu_dir}')\n",
    "\n",
    "# filter singeltons out\n",
    "for sample_path in all_paths:\n",
    "    strip(file_path = sample_path, output_path = otu_chim_filt)\n",
    "    sample_name = sample_path.split('/')[-1].lstrip('otu_').rstrip('.fasta')\n",
    "    filter_rare(path = sample_path, output_path = filt_otu_dir, threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3158c2",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6948bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats before filtering rare otus\n",
    "\n",
    "all_files = os.listdir(filt_otu_dir)\n",
    "all_files = [sample for sample in all_files if \"stripped_otu_\" in sample]\n",
    "all_paths = [filt_otu_dir + '/' + path for path in all_files]\n",
    "\n",
    "before_filt_stats = {}\n",
    "\n",
    "for path in all_paths:\n",
    "    sample_name = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    with open(path, 'rt') as f:\n",
    "        count_ = 0\n",
    "        for line in f:\n",
    "            if '>' in line:\n",
    "                count_ += 1\n",
    "    before_filt_stats[sample_name] = count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats after filtering rare otus\n",
    "\n",
    "all_files = os.listdir(filt_otu_dir)\n",
    "all_files = [sample for sample in all_files if \"nonrare_otu_\" in sample]\n",
    "all_paths = [filt_otu_dir + '/' + path for path in all_files]\n",
    "\n",
    "rare_filt_stats = {}\n",
    "\n",
    "for path in all_paths:\n",
    "    sample_name = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    with open(path, 'rt') as f:\n",
    "        count_ = 0\n",
    "        for line in f:\n",
    "            if '>' in line:\n",
    "                count_ += 1\n",
    "    rare_filt_stats[sample_name] = count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_filt = pd.DataFrame.from_dict(before_filt_stats, orient='index', columns=['before_filt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_filt = pd.DataFrame.from_dict(rare_filt_stats, orient='index', columns=['rare_filt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = before_filt.join(rare_filt)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40884130",
   "metadata": {},
   "source": [
    "# Extract vamp sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be74da",
   "metadata": {},
   "source": [
    "## From filtered (singeltons filtered out) fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3dde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to fasta files\n",
    "all_files = os.listdir(filt_otu_dir)\n",
    "all_files = [sample for sample in all_files if \"nonrare_otu_\" in sample]\n",
    "all_paths = [filt_otu_dir + '/' + path for path in all_files]\n",
    "\n",
    "# getting vampyrellid-specific ids \n",
    "for path in all_paths:\n",
    "    sample_name = path.split('/')[-1].lstrip('nonrare_otu_').rstrip('.fasta')\n",
    "    tax_assign_path = f\"{tax_assign_dir}/blast6_{sample_name}.tab\"\n",
    "    with open(tax_assign_path, 'rt') as f:\n",
    "        # get vamp ids from the tax assignment\n",
    "        vamp_ids = []\n",
    "        for line in f:\n",
    "            if 'Vampyrellida' in line:\n",
    "                vamp_ids.append(line.split('\\t')[0])\n",
    "        # use the vamp ids to extract the vamp-specific sequences from the fasta file\n",
    "        filtered_seqs = []\n",
    "        with open(path, 'rt') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[::-1]:\n",
    "                if not line.startswith('>'):\n",
    "                    sequence = line\n",
    "                else:\n",
    "                    if any([x in line for x in vamp_ids]):\n",
    "                        filtered_seqs.append(line)\n",
    "                        filtered_seqs.append(sequence)\n",
    "        # write the filtered vampyrellid sequences into a fasta file\n",
    "        with open(f'{vamp_spec_dir}/nonrare_otu_{sample_name}.fasta', 'w') as fp:\n",
    "            for seq in filtered_seqs:\n",
    "                fp.write(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd443c",
   "metadata": {},
   "source": [
    "## From unfiltered (singeltons included) fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aaa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to fasta files\n",
    "all_files = os.listdir(otu_chim_filt)\n",
    "all_files = [sample for sample in all_files if \"otu_\" in sample]\n",
    "all_paths = [otu_chim_filt + '/' + path for path in all_files]\n",
    "\n",
    "\n",
    "# getting vampyrellid-specific ids \n",
    "for path in all_paths:\n",
    "    sample_name = path.split('/')[-1].lstrip('otu_').rstrip('.fasta')\n",
    "    tax_assign_path = f'{tax_assign_dir}/blast6_{sample_name}.tab'\n",
    "    with open(tax_assign_path, 'rt') as f:\n",
    "        # get vamp ids from the tax assignment\n",
    "        vamp_ids = []\n",
    "        for line in f:\n",
    "            if 'Vampyrellida' in line:\n",
    "                vamp_ids.append(line.split('\\t')[0])            \n",
    "        # use the vamp ids to extract the vamp-specific sequences from the fasta file\n",
    "        filtered_seqs = []\n",
    "        with open(path, 'rt') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[::-1]:\n",
    "                if not line.startswith('>'):\n",
    "                    sequence = line\n",
    "                else:\n",
    "                    if any([x in line for x in vamp_ids]):\n",
    "                        filtered_seqs.append(line)\n",
    "                        filtered_seqs.append(sequence)\n",
    "        # write the filtered vampyrellid sequences into a fasta file\n",
    "        with open(f'{vamp_spec_dir}/otu_{sample_name}.fasta', 'w') as fp:\n",
    "            for seq in filtered_seqs:\n",
    "                fp.write(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf35d8b",
   "metadata": {},
   "source": [
    "# Filtering rare OTUs from extracted 18S for the phylogenetic placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "\n",
    "project = 'Jamy_2022'\n",
    "cell = 'cell'\n",
    "marker = 'rDNA'\n",
    "sim = 'sim97'\n",
    "raw_data = '../raw_data'\n",
    "otu_preclust_dir = f'{raw_data}/OTU_preclust/{project}/{marker}/{cell}/{sim}'\n",
    "tax_assign_dir = f'{raw_data}/tax_assign_results/{project}/{marker}/{cell}/{sim}'\n",
    "filt_otu_dir = f'{raw_data}/OTU_filtered/{project}/{marker}/{cell}/{sim}'\n",
    "vamp_spec_dir = f'{raw_data}/vamp_specific_seqs/{project}/{marker}/{cell}/{sim}'\n",
    "otu_chim_filt = f'{raw_data}/OTU_nonchimeric/{project}/{marker}/{cell}/{sim}'\n",
    "extracted_18S = f'{raw_data}/extracted_18S/{project}/{marker}/{cell}/{sim}'\n",
    "filt_otu_dir_18S = f'{raw_data}/OTU_filtered/{project}/18S_from_rDNA/{cell}/{sim}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4ea4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "\n",
    "\n",
    "def strip(file_path, output_path):\n",
    "    '''\n",
    "    Remove line breaks in FASTA files, so it will be easier to filter singeltons in the next step\n",
    "    '''\n",
    "    seqs = []\n",
    "    # read a file and stripped it\n",
    "    with open(file_path,'rt') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('>'):\n",
    "                seqs.append('\\n' + line)\n",
    "            else:\n",
    "                line_cleaned = line.rstrip()\n",
    "                seqs.append(line_cleaned)\n",
    "        seqs[0] = seqs[0].lstrip()\n",
    "    # write the file into fasta\n",
    "    # get sample names:\n",
    "    sample_name = file_path.split('/')[-1].lstrip('otu_').rstrip('.fasta')\n",
    "    with open(f'{output_path}/{sample_name}.fasta', 'w') as fp:\n",
    "        for seq in seqs:\n",
    "            fp.write(seq)\n",
    "            \n",
    "            \n",
    "def filter_rare(path, output_path, threshold=1):\n",
    "    seqs_nonsingl = []\n",
    "    with open(path,'rt') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[::-1]:\n",
    "            if not line.startswith('>'):\n",
    "                seq_ = line\n",
    "            if ('>' in line):\n",
    "                abundance = int(line.split('=')[-1].rstrip('\\n'))\n",
    "                if abundance > threshold:\n",
    "#             if ('>' in line) and (not line.endswith(f'seqs={threshold}\\n')):\n",
    "                    seqs_nonsingl.append(line)\n",
    "                    seqs_nonsingl.append(seq_)\n",
    "    # write the file into fasta\n",
    "    # get sample name for our data:\n",
    "    sample_name = path.split('/')[-1].rstrip('.fasta')\n",
    "    with open(f'{output_path}/nonrare_otu_{sample_name}.fasta', 'w') as fp:\n",
    "        for seq in seqs_nonsingl:\n",
    "            fp.write(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "405a60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths\n",
    "all_files = os.listdir(extracted_18S)\n",
    "all_paths = [extracted_18S + '/' + path for path in all_files]\n",
    "all_paths = [path for path in all_paths if '.fasta' in path]\n",
    "all_paths\n",
    "\n",
    "# filter singeltons out\n",
    "for sample_path in all_paths:\n",
    "    strip(file_path = sample_path, output_path = extracted_18S)\n",
    "    filter_rare(path = sample_path, output_path = filt_otu_dir, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365dd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7845fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723d836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
